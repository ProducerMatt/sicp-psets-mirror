<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">
<!--Converted with LaTeX2HTML 96.1-h (September 30, 1996) by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds -->
<HTML>

<!-- Mirrored from groups.csail.mit.edu/mac/classes/6.001/ST98/psets/ps8web/ps8-speech/ps8-speech.html by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 06 Aug 2022 23:00:30 GMT -->
<HEAD>
<TITLE>No Title</TITLE>
<META NAME="description" CONTENT="No Title">
<META NAME="keywords" CONTENT="ps8-speech">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<LINK REL=STYLESHEET HREF="ps8-speech.css">
</HEAD>
<BODY LANG="EN" >
 <A NAME="tex2html2" HREF="node1.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="http://swissnet.ai.mit.edu/latex2html-lib/icons/next_motif.gif"></A> <IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="http://swissnet.ai.mit.edu/latex2html-lib/icons/up_motif_gr.gif"> <IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="http://swissnet.ai.mit.edu/latex2html-lib/icons/previous_motif.gif">   <BR>
<B> Next:</B> <A NAME="tex2html3" HREF="node1.html">1. Background</A>
<BR> <P>
<P>
<center>
MASSACHVSETTS INSTITVTE OF TECHNOLOGY <BR> 
Department of Electrical Engineering and Computer Science <BR> 
6.001--Structure and Interpretation of Computer Programs <BR> 
Spring Semester, 1998 <BR> 
<P>
<B>Problem Set 8</B>
</center>
<P>
<UL>
<LI> Issued:  Tuesday, March 31, 1998
<LI> Tutorial preparation for: Week of April 6
<LI> Written solutions due: Friday, April 10 in recitation
<LI> Reading: Read
      section 3.4 before lecture on April 2.  Read section 4.1
      before lecture on April 9.
<LI> Reminder: Quiz 2 will be held on Tuesday evening, April 14.
      More information will be distributed in lecture on Tuesday,
      April 7. 
</UL>
<P>
<B>Streams and Speech Recognition</B>

<P>
<P>
<P>
In lecture on March 31, we looked at streams and at some of the
computational approaches that are associated with these data
structures.  We saw that the key concept behind streams was to
decouple the apparent order of evaluation of expressions from the
actual order evaluation in the computer.  By doing so, we can execute
processes without having to first generate all the stream elements.
This is a useful variation on our earlier approaches to
computation.  There are many applications that are naturally
viewed in terms of processing  continuous sequences (or streams) of values
(e.g. electrical signals, sonar, radar, sound, etc.).
<P>
Consider speech recognition.  The input to a speech recognizer might
be a stream of frequencies based on the interaction of sound waves
generated by the speaker with some receiver (e.g. a taut drum that
converts wave fronts to vibrations that can be converted to an
electrical signal).  The goal is to convert the electrical
signal that represents the sound waves into words.  In traditional
approaches to speech recognition, there is an intermediate step in
which the stream of vibrations is first converted into subunits of
actual spoken words, called <EM>phonemes</EM>.  These represent the units of
sound that comprise spoken words.
<P>
For example, figure&nbsp;<A HREF="ps8-speech.html#figspectrum">1</A> shows a sample speech input.
<P>
<P><A NAME="274">&#160;</A><A NAME="figspectrum">&#160;</A><IMG WIDTH=799 HEIGHT=337 ALIGN=BOTTOM ALT="figure131" SRC="img1.gif"><BR>
<STRONG>Figure 1:</STRONG> 
The picture illustrates three useful representations for human speech
during computer speech recognition.  The top display results from the
short-time Fourier analysis of the speech signal and depicts the
varying distribution of spectral energy across time and frequency
(darker means more energy).  The next display is the amplitude of the
waveform, recorded and digitized at 16,000 samples per second.
Finally, the transcription shows which words were actually spoken, and
their corresponding alignments in time (the time axis is measured in
seconds).
<BR>
<P>
<P>
Speech recognition would be simple if there was a clear transformation
from vibrations to phonemes, and then to words.  Unfortunately, in
most normal situations, the speech signal is noisyand ambiguous.  This
means first that the interpretation of the vibration stream into
phonemes is not clearcut--there may be several phonemes that could
correspond to the detected vibrations.  Second, the breaks between
words may not be clear, so that one has to worry about where to
separate the boundaries of the phonemes. Indeed, in the example shown
in the figure, there is no obvious silence or gap between ``he'' and
``ate''.  Because of these phenomena, building good speech-recognition
systems is very difficult.
<P>
<BR> <HR>
<UL><A NAME="CHILD_LINKS">&#160;</A>
<LI> <A NAME="tex2html4" HREF="node1.html#SECTION00010000000000000000">1. Background</A>
<LI> <A NAME="tex2html5" HREF="node2.html#SECTION00020000000000000000">2. Tutorial Exercises</A>
<LI> <A NAME="tex2html6" HREF="node3.html#SECTION00030000000000000000">3. Programming Assignment</A>
<LI> <A NAME="tex2html7" HREF="node4.html#SECTION00040000000000000000">  About this document ... </A>
</UL>
<HR><A NAME="tex2html2" HREF="node1.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="http://swissnet.ai.mit.edu/latex2html-lib/icons/next_motif.gif"></A> <IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="http://swissnet.ai.mit.edu/latex2html-lib/icons/up_motif_gr.gif"> <IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="http://swissnet.ai.mit.edu/latex2html-lib/icons/previous_motif.gif">   <BR>
<B> Next:</B> <A NAME="tex2html3" HREF="node1.html">1. Background</A>
<P><ADDRESS>
<I>Hal Abelson <BR>
Fri Mar 27 14:32:25 EST 1998</I>
</ADDRESS>
</BODY>

<!-- Mirrored from groups.csail.mit.edu/mac/classes/6.001/ST98/psets/ps8web/ps8-speech/ps8-speech.html by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 06 Aug 2022 23:00:36 GMT -->
</HTML>
